{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine doesn't grow on trees!\n",
    "\n",
    "Instead of predicting a continuous variable, like price, I'm going to instead shift gears and see if it is possible to predict whether a wine is expensive or not based on its features. For the purposes of this project, I'm going to define expensive as whether or not the wine is priced greater than $100, as this seems like a lot to spend on a bottle. I'm going to begin by running a decision tree as they're intuitive to understand and tweak it as necessary to improve the accuracy and recall metrics. I'll be looking at the accuracy and recall metrics in particular, and will be running a 10-fold cross-validation to ensure the stability of the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "cab_df2 = pd.read_csv('./cablist4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new target variable based on price\n",
    "#$100 seems like a lot to spend on a bottle of wine, so that will be my threshold\n",
    "\n",
    "cab_df2['HighPrice_Ind'] = cab_df2['PriceRetail'].apply(lambda x: 1 if x >= 100.00 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Vintage', 'RatingScore', 'UnqWordInd', 'Attribute_94+ Rated Wine', \\\n",
    "            'Attribute_Boutique Wines', 'Attribute_Business Gifts',\\\n",
    "            'Attribute_Collectible Wines', 'Attribute_Earthy &amp; Spicy', 'Attribute_Great Bottles to Give',\\\n",
    "            'Attribute_Green Wines', 'Attribute_Kosher Wines', 'Attribute_Older Vintages', \\\n",
    "            'Attribute_Private Cellar List', 'Attribute_Rich &amp; Creamy', 'Attribute_Screw Cap Wines', \\\n",
    "            'Attribute_Smooth &amp; Supple', 'Region_California', 'Region_Italy', 'Region_South Africa',\\\n",
    "            'Region_South America', 'Region_Spain', 'Region_Washington']\n",
    "target = ['HighPrice_Ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cab_df2[features]\n",
    "y = cab_df2.HighPrice_Ind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=20,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=39, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "treeclf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vintage</td>\n",
       "      <td>0.105209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RatingScore</td>\n",
       "      <td>0.687225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UnqWordInd</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attribute_94+ Rated Wine</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attribute_Boutique Wines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Attribute_Business Gifts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Attribute_Collectible Wines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Attribute_Earthy &amp;amp; Spicy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Attribute_Great Bottles to Give</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Attribute_Green Wines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Attribute_Kosher Wines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Attribute_Older Vintages</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Attribute_Private Cellar List</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Attribute_Rich &amp;amp; Creamy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Attribute_Screw Cap Wines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Attribute_Smooth &amp;amp; Supple</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Region_California</td>\n",
       "      <td>0.207565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Region_Italy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Region_South Africa</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Region_South America</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Region_Spain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Region_Washington</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature  importance\n",
       "0                           Vintage    0.105209\n",
       "1                       RatingScore    0.687225\n",
       "2                        UnqWordInd    0.000000\n",
       "3          Attribute_94+ Rated Wine    0.000000\n",
       "4          Attribute_Boutique Wines    0.000000\n",
       "5          Attribute_Business Gifts    0.000000\n",
       "6       Attribute_Collectible Wines    0.000000\n",
       "7      Attribute_Earthy &amp; Spicy    0.000000\n",
       "8   Attribute_Great Bottles to Give    0.000000\n",
       "9             Attribute_Green Wines    0.000000\n",
       "10           Attribute_Kosher Wines    0.000000\n",
       "11         Attribute_Older Vintages    0.000000\n",
       "12    Attribute_Private Cellar List    0.000000\n",
       "13      Attribute_Rich &amp; Creamy    0.000000\n",
       "14        Attribute_Screw Cap Wines    0.000000\n",
       "15    Attribute_Smooth &amp; Supple    0.000000\n",
       "16                Region_California    0.207565\n",
       "17                     Region_Italy    0.000000\n",
       "18              Region_South Africa    0.000000\n",
       "19             Region_South America    0.000000\n",
       "20                     Region_Spain    0.000000\n",
       "21                Region_Washington    0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature':features, 'importance':treeclf.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model seems to do a decent job predicting which wines are high priced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Testing Results \n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not high priced       0.82      0.84      0.83       560\n",
      "    high priced       0.73      0.71      0.72       344\n",
      "\n",
      "    avg / total       0.79      0.79      0.79       904\n",
      "\n",
      "Confusion Matrix is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[470,  90],\n",
       "       [101, 243]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds = treeclf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y_test, preds,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately it isn't stable, as the cross-validation shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score Summary:\n",
      "[ 1.          0.92929293  0.92929293  0.91919192  0.          0.68686869\n",
      "  0.26262626  0.          0.05050505  0.        ]\n",
      "0.477777777778\n",
      "Accuracy Score Summary:\n",
      "[ 0.36131387  0.50364964  0.56569343  0.47810219  0.63868613  0.72627737\n",
      "  0.66423358  0.63868613  0.65693431  0.63736264]\n",
      "0.58709392797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "recall_scores = cross_val_score(treeclf, x, y, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(treeclf, x, y, cv=10, scoring='accuracy')\n",
    "print \"Recall Score Summary:\"\n",
    "print recall_scores\n",
    "print recall_scores.mean()\n",
    "\n",
    "print \"Accuracy Score Summary:\"\n",
    "print accuracy_scores\n",
    "print accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's restrict features in hopes of improving stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features2 = ['RatingScore','Region_California',\\\n",
    "            'Vintage']\n",
    "target = ['PriceRetail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Testing Results \n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not high priced       0.82      0.84      0.83       560\n",
      "    high priced       0.73      0.71      0.72       344\n",
      "\n",
      "    avg / total       0.79      0.79      0.79       904\n",
      "\n",
      "Confusion Matrix is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[470,  90],\n",
       "       [101, 243]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = cab_df2[features2]\n",
    "y2 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "treeclf.fit(x2, y2)\n",
    "\n",
    "pred2 = treeclf.predict(x2_test)\n",
    "cm = confusion_matrix(y2_test, pred2)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y2_test, pred2,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score Summary:\n",
      "[ 1.          0.92929293  0.92929293  0.91919192  0.          0.62626263\n",
      "  0.26262626  0.          0.05050505  0.        ]\n",
      "0.471717171717\n",
      "Accuracy Score Summary:\n",
      "[ 0.36131387  0.50364964  0.56569343  0.47810219  0.63868613  0.76277372\n",
      "  0.66423358  0.63868613  0.65693431  0.63736264]\n",
      "0.590743563006\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(treeclf, x2, y2, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(treeclf, x2, y2, cv=10, scoring='accuracy')\n",
    "print \"Recall Score Summary:\"\n",
    "print recall_scores\n",
    "print recall_scores.mean()\n",
    "\n",
    "print \"Accuracy Score Summary:\"\n",
    "print accuracy_scores\n",
    "print accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RatingScore</td>\n",
       "      <td>0.687225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Region_California</td>\n",
       "      <td>0.207565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vintage</td>\n",
       "      <td>0.105209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "0        RatingScore    0.687225\n",
       "1  Region_California    0.207565\n",
       "2            Vintage    0.105209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature':features, 'importance':treeclf.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A forest may be better than the tree -- Trying a random forest to improve results\n",
    "I'm not that satisfied with the classification tree output, so I'm going to try some random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Testing Results \n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not high priced       0.79      0.91      0.85       560\n",
      "    high priced       0.80      0.61      0.69       344\n",
      "\n",
      "    avg / total       0.80      0.79      0.79       904\n",
      "\n",
      "Confusion Matrix is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[509,  51],\n",
       "       [135, 209]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = cab_df2[features]\n",
    "y3 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "rfc.fit(x3, y3)\n",
    "\n",
    "pred3 = rfc.predict(x3_test)\n",
    "cm = confusion_matrix(y3_test, pred3)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y3_test, pred3,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score Summary:\n",
      "[ 1.          0.92929293  0.92929293  0.91919192  0.19191919  0.54545455\n",
      "  0.15151515  0.01010101  0.05050505  0.        ]\n",
      "0.472727272727\n",
      "Accuracy Score Summary:\n",
      "[ 0.36131387  0.50364964  0.72627737  0.47810219  0.7080292   0.78832117\n",
      "  0.67518248  0.64233577  0.65693431  0.63736264]\n",
      "0.617750862276\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(rfc, x3, y3, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(rfc, x3, y3, cv=10, scoring='accuracy')\n",
    "print \"Recall Score Summary:\"\n",
    "print recall_scores\n",
    "print recall_scores.mean()\n",
    "\n",
    "print \"Accuracy Score Summary:\"\n",
    "print accuracy_scores\n",
    "print accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Gradient Boost this wine!\n",
    "The random forest barely improved the results, and I'd like to try to do better, so I'm going to give Gradient Boosting a try. The logic behind this is that this algorithm will generate a sequence of models that build upon themselves to correct their mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Testing Results \n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "not high priced       0.81      0.90      0.85       560\n",
      "    high priced       0.80      0.66      0.72       344\n",
      "\n",
      "    avg / total       0.81      0.81      0.80       904\n",
      "\n",
      "Confusion Matrix is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[505,  55],\n",
       "       [118, 226]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = cab_df2[features]\n",
    "y3 = cab_df2.HighPrice_Ind.values\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=.33, random_state=39)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=3, min_samples_leaf=20, random_state=39)\n",
    "gbc.fit(x3, y3)\n",
    "\n",
    "pred3 = gbc.predict(x3_test)\n",
    "cm = confusion_matrix(y3_test, pred3)\n",
    "\n",
    "print(\"Train Testing Results \\n\\n\")\n",
    "\n",
    "print(classification_report(y3_test, pred3,\n",
    "                         target_names=['not high priced', 'high priced']))\n",
    "\n",
    "print('Confusion Matrix is:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score Summary:\n",
      "[ 1.          0.57575758  0.87878788  0.75757576  0.47474747  0.41414141\n",
      "  0.15151515  0.07070707  0.06060606  0.        ]\n",
      "0.438383838384\n",
      "Accuracy Score Summary:\n",
      "[ 0.4379562   0.37226277  0.74817518  0.51824818  0.80656934  0.69343066\n",
      "  0.54014599  0.66423358  0.64233577  0.63736264]\n",
      "0.60607203016\n"
     ]
    }
   ],
   "source": [
    "recall_scores = cross_val_score(gbc, x3, y3, cv=10, scoring='recall')\n",
    "accuracy_scores = cross_val_score(gbc, x3, y3, cv=10, scoring='accuracy')\n",
    "print \"Recall Score Summary:\"\n",
    "print recall_scores\n",
    "print recall_scores.mean()\n",
    "\n",
    "print \"Accuracy Score Summary:\"\n",
    "print accuracy_scores\n",
    "print accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion:\n",
    "\n",
    "The decision tree models did a mediocre job of predicting whether or not a bottle of wine will be priced above $100. While the recall and accuracy were decent for a single iteration of the model, their stability across multiple iterations was challenged and produced sub-optimal results. I think this can be improved, so I'm going to try some new modeling techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
